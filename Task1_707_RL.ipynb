{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "707 Coursework- Task 1: The Environment\n",
    "\n",
    "This environment recreates the original Pacman game. The environment is a grid filled with pellets (or breadcrumbs) which the pacman agent must collect. The environment also contains some barriers which the agent must learn to avoid/walk around, as it cannot pass through them. The element of stochasticity in this environment is a ghost, which walks around the grid randomly. The pacman agent must avoid the ghost in order to win the game. \n",
    "Moreover, the breadcrumbs in the environment are also placed in random locations of the grid at the start of each episode. \n",
    "\n",
    "If the pacman agent collects all the pellets in the environment and does not encounter the ghost, pacman wins and the episode terminates. However, if pacman moves to the cell with the ghost, pacman dies and the game terminates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    '''\n",
    "    creating the pacman environment\n",
    "    '''\n",
    "    def __init__(self, m, n):\n",
    "        self.environment = np.zeros((m, n))\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.state_space = [i for i in range(self.m * self.n)]\n",
    "        self.action_space = {'U': -self.m, 'D': self.m, 'L': -1, 'R': 1}\n",
    "        self.possible_actions = ['U', 'D', 'L', 'R']\n",
    "        self.add_barriers()\n",
    "        self.agent_position = 24\n",
    "        self.environment[3][3] = 1\n",
    "        self.ghost_position = 39\n",
    "        self.add_breadcrumbs()\n",
    "\n",
    "    def add_barriers(self):\n",
    "        '''\n",
    "        this function add barriers in the grid space\n",
    "        '''\n",
    "        for i in range(7):\n",
    "            self.environment[i][0] = 2\n",
    "            self.environment[i][6] = 2\n",
    "            self.environment[0][i] = 2\n",
    "            self.environment[6][i] = 2\n",
    "        self.environment[2][3] = 2\n",
    "        self.environment[2][4] = 2\n",
    "        self.environment[3][4] = 2\n",
    "        self.environment[4][3] = 2\n",
    "        self.environment[4][4] = 2\n",
    "\n",
    "    def add_breadcrumbs(self, ):\n",
    "        '''\n",
    "        this function adds breadcrumbs/pellets in the grid space which pacman has to collect\n",
    "        '''\n",
    "        self.breadcrumbs = []\n",
    "        i = 1\n",
    "        while i < 11:\n",
    "            position = random.randint(0, 48)\n",
    "            x, y = self.get_row_and_column(position)\n",
    "            if self.environment[x][y] == 0 and position not in self.breadcrumbs:\n",
    "                self.breadcrumbs.append(position)\n",
    "                i += 1\n",
    "\n",
    "    def is_terminal_state(self, state):\n",
    "        '''\n",
    "        This function returns true if the state is terminal.\n",
    "        For the state to be terminal pacman must collect all pellets\n",
    "        '''\n",
    "        if self.number_of_breadcrumbs() == 0:\n",
    "            return state\n",
    "        if self.ghost_position == self.agent_position:\n",
    "            return state\n",
    "\n",
    "\n",
    "    def number_of_breadcrumbs(self):\n",
    "        '''\n",
    "        Returns the number of pellets left in the environment\n",
    "        '''\n",
    "        return len(self.breadcrumbs)\n",
    "\n",
    "    def get_row_and_column(self, position):\n",
    "        '''\n",
    "        Returns the coordinates of the agent on the grid\n",
    "        '''\n",
    "        x = position // self.m\n",
    "        y = position % self.n\n",
    "        return x, y\n",
    "\n",
    "    def set_state(self, state):\n",
    "        '''\n",
    "        When pacman makes a new move, its position becomes the new state\n",
    "        and the old one becomes 0 (empty cell)\n",
    "        '''\n",
    "        x, y = self.get_row_and_column(self.agent_position)\n",
    "        self.environment[x][y] = 0\n",
    "\n",
    "        self.agent_position = state\n",
    "        x, y = self.get_row_and_column(self.agent_position)\n",
    "        self.environment[x][y] = 1\n",
    "\n",
    "    def off_grid_move(self, newState, oldState):\n",
    "        '''\n",
    "        If pacman tries to go off the grid it must receive a negative reward,\n",
    "        this is becuase the outer perimeter of the grid is formed by barriers.\n",
    "        This function returns a boolean value of signaling if pacman has tried\n",
    "        to make an illegal move, attempting to move outside the 5x5 RL environment.\n",
    "        '''\n",
    "        x, y = self.get_row_and_column(newState)\n",
    "        if self.environment[x][y] == 2:\n",
    "            print(\"off grid\")\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def step(self, action):\n",
    "        '''\n",
    "        This function implements the agents movement from one cell to the next. The reward at each time step is -100.\n",
    "        It checks that the chosen action is not off the grid, and then it replaces the agent's co-ordinates from the current cell to the next cell\n",
    "        which the agent has decided to move to. \n",
    "        This function also checks that if the agent moves to a location with the breadcrumb it collects it.\n",
    "        if the agent is not on the ghost's position, the ghost can now move.\n",
    "        Lastly, the reward is calculated and given to the agent. \n",
    "        '''\n",
    "        resulting_state = self.agent_position + self.action_space[self.possible_actions[action]]\n",
    "        reward = -100\n",
    "        numberOfBreadcrumbs = self.number_of_breadcrumbs()\n",
    "        if not self.off_grid_move(resulting_state, self.agent_position):\n",
    "            self.set_state(resulting_state)\n",
    "            if self.agent_position in self.breadcrumbs:\n",
    "                self.breadcrumbs.remove(self.agent_position)\n",
    "            if self.agent_position != self.ghost_position:\n",
    "                self.ghost_move()\n",
    "            reward = self.reward(self.agent_position, action, numberOfBreadcrumbs)\n",
    "        return (self.get_row_and_column(self.agent_position), tuple(self.breadcrumbs) if len(self.breadcrumbs) < 2 else len(self.breadcrumbs), self.get_row_and_column(self.ghost_position)), reward, self.is_terminal_state(self.agent_position)\n",
    "\n",
    "    def ghost_move(self):\n",
    "        '''\n",
    "        This method's functionality is to move the ghost around the grid.\n",
    "        '''\n",
    "        self.ghost_position = self.ghost_position + self.action_space[self.possible_actions[self.action_space_sample(self.ghost_position)]]\n",
    "\n",
    "\n",
    "    def reward(self, state, action, numberOfBreadcrumbs):\n",
    "        '''\n",
    "        The reward function is responsable for assigning the rewards to the agent.\n",
    "        The reward value is dependent on what action the agent performs:\n",
    "        if the agent moves onto the ghost's cell, the reward is -1000;\n",
    "        if the game is terminated successfully, pacman receives 1000;\n",
    "        else the agent receives -1 at each timestep.\n",
    "        Moreover, the agent will get a negative reward as it gets closer to the ghost,\n",
    "        & receives a reward of 10 if there are more breadcrumbs to collect.\n",
    "        '''\n",
    "        if self.agent_position == self.ghost_position:\n",
    "            reward = -1000\n",
    "        elif self.is_terminal_state(state):\n",
    "            reward = 1000\n",
    "        else:\n",
    "            reward = -1\n",
    "            state_after_another_action = state\n",
    "            x, y = self.get_row_and_column(state_after_another_action)\n",
    "            for i in range(3):\n",
    "                state_after_another_action = state_after_another_action + self.action_space[self.possible_actions[action]]\n",
    "                object = self.environment[x][y]\n",
    "                if state_after_another_action == self.ghost_position:\n",
    "                    reward = -100/(i+1)\n",
    "                    break\n",
    "                elif object == 2:\n",
    "                    break\n",
    "            if reward == -1 and numberOfBreadcrumbs != self.number_of_breadcrumbs():\n",
    "                reward = 10\n",
    "        return reward\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        This method resets the whole environment from the start\n",
    "        for each episode\n",
    "        '''\n",
    "        self.agent_position = 24\n",
    "        self.environment = np.zeros((self.m, self.n))\n",
    "        self.add_barriers()\n",
    "        self.environment[3][3] = 1\n",
    "        self.ghost_position = 39\n",
    "        self.add_breadcrumbs()\n",
    "        return self.agent_position\n",
    "\n",
    "    def render(self):\n",
    "        '''\n",
    "        This function is a simple rendering of the environment in the console,\n",
    "        this function is mostly used for debugging and to give a visual demonstration\n",
    "        of how the environment looks like\n",
    "        '''\n",
    "        print('--------------------------------------------------')\n",
    "        i = 0\n",
    "        for row in self.environment:\n",
    "            for col in row:\n",
    "                if i == self.ghost_position:\n",
    "                    print('G', end='\\t')\n",
    "                elif col == 1:\n",
    "                    print('P', end='\\t')\n",
    "                elif col == 2:\n",
    "                    print('|', end='\\t')\n",
    "                elif i in self.breadcrumbs:\n",
    "                    print('*', end='\\t')\n",
    "                elif col == 0:\n",
    "                    print('-', end='\\t')\n",
    "                i += 1\n",
    "            print('\\n')\n",
    "        print('--------------------------------------------------')\n",
    "\n",
    "    def action_space_sample(self, position):\n",
    "        '''\n",
    "        This function returns a random sample of the possible actions, as long as\n",
    "        the action does not result in encountering a barrier\n",
    "        '''\n",
    "        actions = []\n",
    "        for action in range(len(self.possible_actions)):\n",
    "            next_state = position + self.action_space[self.possible_actions[action]]\n",
    "            x, y = self.get_row_and_column(next_state)\n",
    "            if self.environment[x][y] != 2:\n",
    "                actions.append(action)\n",
    "        return np.random.choice(actions)\n",
    "\n",
    "\n",
    "    def max_action(self, Q, state):\n",
    "        '''\n",
    "        This function returns the action with the maximum Q-value in the Q-table\n",
    "        '''\n",
    "        values = Q[state]\n",
    "        for action in range(len(values)):\n",
    "            next_state = self.agent_position + self.action_space[self.possible_actions[action]]\n",
    "            x, y = self.get_row_and_column(next_state)\n",
    "            if self.environment[x][y] == 2:\n",
    "                values[action] = -np.inf\n",
    "        max_reward = np.max(values)\n",
    "        actions = []\n",
    "        for action in range(len(values)):\n",
    "            if values[action] == max_reward:\n",
    "                actions.append(action)\n",
    "        return np.random.choice(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\t|\t|\t|\t|\t|\t|\t\n",
      "\n",
      "|\t*\t*\t*\t*\t-\t|\t\n",
      "\n",
      "|\t*\t-\t|\t|\t*\t|\t\n",
      "\n",
      "|\t-\t*\tP\t|\t*\t|\t\n",
      "\n",
      "|\t*\t-\t|\t|\t-\t|\t\n",
      "\n",
      "|\t*\t-\t-\tG\t-\t|\t\n",
      "\n",
      "|\t|\t|\t|\t|\t|\t|\t\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = Environment(7, 7)\n",
    "\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
