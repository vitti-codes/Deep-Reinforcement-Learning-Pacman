# Deep Reinforcement Learning using the Pacman game

This project is divided into 3 tasks. 
The first is the implementation of a simplified version of the Pacman environment, where a 7x7 grid contains 5 obstacles (or barriers), a ghost which moves randomly, and 10 pellets which are placed randomly at the start of each game.
Pacman's aim is to collect all the pellets (or breadcrumbs) in its environment, while avoiding the ghost. 

The second task uses the previously implemented environment and uses the Q-Learning algorithm, employing the Epsilon-Greedy Policy

The last task entails the implementation of the SAC-Discrete algorithm, described by Christodoulou. This algorithm takes inspiration from the Soft Actor Critic algorithm, however it is adjusted to fit discrete action settings. 
This final task was a pair-programming excercise, the team members are Geoffrey Payne and myself. 

